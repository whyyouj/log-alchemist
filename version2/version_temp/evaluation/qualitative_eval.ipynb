{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import ollama\n",
    "import csv\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class LanguageModelEvaluator:\n",
    "    def __init__(self, model_name: str, model_type: str = 'ollama'):\n",
    "        self.model_name = model_name\n",
    "        self.model_type = model_type\n",
    "        self.model = self._load_model()\n",
    "        # Using the same model for evaluation for now, can change later with our model\n",
    "        self.evaluator_model = self.model\n",
    "\n",
    "    def _load_model(self):\n",
    "        if self.model_type == 'ollama':\n",
    "            return ollama.Client()\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Model type {self.model_type} not supported\")\n",
    "\n",
    "    def generate_response(self, prompt: str, context: str = None) -> str:\n",
    "        if self.model_type == 'ollama':\n",
    "            response = self.model.chat(model=self.model_name, messages=[\n",
    "                {\n",
    "                    'role': 'system',\n",
    "                    'content': f\"You are an AI assistant analyzing log files. Here's the log content:\\n\\n{context}\\n\\nAnswer the following question based on this log.\"\n",
    "                },\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': prompt,\n",
    "                }\n",
    "            ])\n",
    "            return response['message']['content']\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Model type {self.model_type} not supported\")\n",
    "\n",
    "    def evaluate_response(self, question: str, response: str, reference_answer: str, rubric: str) -> Dict[str, any]:\n",
    "        # Prepare the evaluation prompt\n",
    "        evaluation_prompt = f\"\"\"\n",
    "You are an expert evaluator. Your task is to evaluate the following response to a question based on the reference answer and the provided rubric. Provide a score and feedback.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Response: {response}\n",
    "\n",
    "Reference Answer: {reference_answer}\n",
    "\n",
    "Rubric:\n",
    "{rubric}\n",
    "\n",
    "Please provide your evaluation as follows, grading the response of the language model with the rubric relative to the reference answer:\n",
    "Score: [1-5]\n",
    "Feedback: [Your detailed feedback]\n",
    "\n",
    "Remember, the score should be an integer between 1 and 5.\n",
    "\n",
    "Evaluation:\n",
    "\"\"\"\n",
    "        # Generating evaluation \n",
    "        eval_response = self.evaluator_model.chat(model=self.model_name, messages=[\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': \"You are an expert evaluator on the responses produced by language models.\"\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': evaluation_prompt,\n",
    "            }\n",
    "        ])\n",
    "        eval_text = eval_response['message']['content']\n",
    "\n",
    "        # Extracting the score and feedback\n",
    "        score_match = re.search(r\"Score:\\s*(\\d+)\", eval_text)\n",
    "        feedback_match = re.search(r\"Feedback:\\s*(.*)\", eval_text, re.DOTALL)\n",
    "\n",
    "        if score_match:\n",
    "            score = int(score_match.group(1))\n",
    "        else:\n",
    "            score = None\n",
    "\n",
    "        if feedback_match:\n",
    "            feedback = feedback_match.group(1).strip()\n",
    "        else:\n",
    "            feedback = None\n",
    "\n",
    "        return {\n",
    "            'score': score,\n",
    "            'feedback': feedback,\n",
    "            'evaluation_text': eval_text\n",
    "        }\n",
    "\n",
    "    def read_log_file(self, file_path: str) -> str:\n",
    "        file_path = Path(file_path)\n",
    "        file_extension = file_path.suffix.lower()\n",
    "\n",
    "        if file_extension in ['.txt', '.log']:\n",
    "            with open(file_path, 'r') as f:\n",
    "                return f.read()\n",
    "        elif file_extension == '.csv':\n",
    "            log_content = []\n",
    "            with open(file_path, 'r') as f:\n",
    "                csv_reader = csv.reader(f)\n",
    "                for row in csv_reader:\n",
    "                    log_content.append(','.join(row))\n",
    "                return '\\n'.join(log_content)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
    "\n",
    "    def evaluate(self, log_file: str, ground_truth_file: str, prompts: List[str], metric_names: List[str]) -> Dict[str, Dict[str, any]]:\n",
    "        log_content = self.read_log_file(log_file)\n",
    "\n",
    "        with open(ground_truth_file, 'r') as f:\n",
    "            ground_truth = json.load(f)\n",
    "\n",
    "        # Define the scoring rubric\n",
    "        score_rubric = \"\"\"\n",
    "Score 1: The response is inaccurate or irrelevant to the question.\n",
    "Score 2: The response has some relevance but contains significant inaccuracies or omissions.\n",
    "Score 3: The response is generally accurate but lacks some important details.\n",
    "Score 4: The response is accurate and includes most of the important details.\n",
    "Score 5: The response is comprehensive, accurate, and addresses all aspects of the question thoroughly.\n",
    "\"\"\"\n",
    "\n",
    "        results = {}\n",
    "        for prompt, metric_name in zip(prompts, metric_names):\n",
    "            model_response = self.generate_response(prompt, log_content)\n",
    "            reference_answer = ground_truth.get(metric_name, \"\")\n",
    "            print(f\"Prompt: {prompt}\")\n",
    "            print(f\"Model Response: {model_response}\")\n",
    "            print(f\"Reference Answer: {reference_answer}\")\n",
    "\n",
    "            evaluation = self.evaluate_response(prompt, model_response, reference_answer, score_rubric)\n",
    "            print(f\"Score: {evaluation['score']}\")\n",
    "            print(f\"Feedback: {evaluation['feedback']}\\n\")\n",
    "\n",
    "            results[metric_name] = {\n",
    "                'score': evaluation['score'],\n",
    "                'feedback': evaluation['feedback'],\n",
    "                'model_response': model_response,\n",
    "                'reference_answer': reference_answer\n",
    "            }\n",
    "            \n",
    "        \n",
    "\n",
    "        return results\n",
    "\n",
    "    def save_results(self, results: Dict[str, Dict[str, any]], output_file: str = None) -> str:\n",
    "        if output_file is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_file = f\"./results/qualitative_evaluation_results_{timestamp}.json\"\n",
    "\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "        output = {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"model_type\": self.model_type,\n",
    "            \"evaluation_time\": datetime.now().isoformat(),\n",
    "            \"results\": results\n",
    "        }\n",
    "\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(output, f, indent=2)\n",
    "\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "        return output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Why did the system restart?\n",
      "Model Response: According to the log, the system restarted twice:\n",
      "\n",
      "1. The first restart occurred at 10:00:01 (initial system startup) is not relevant here.\n",
      "2. The second restart occurred after a \"System crash detected\" event at 11:00:00.\n",
      "\n",
      "This suggests that a system crash was the reason for the restart. However, there isn't any additional information in the log about the cause of the crash.\n",
      "Reference Answer: The system restarted due to a scheduled maintenance update at 02:00 AM.\n",
      "Score: 2\n",
      "Feedback: The response has some relevance to the question as it mentions a system restart and provides details from the log. However, it is inaccurate in identifying the reason for the restart (system crash detected vs scheduled maintenance update). Additionally, it overlooks the timing mentioned in the reference answer (02:00 AM) and only focuses on the time of the second restart (11:00:00) which is not relevant to the question. The response also jumps to a conclusion about the cause of the system crash without supporting evidence from the log. Overall, while it attempts to engage with the question, it demonstrates significant inaccuracies and omissions compared to the reference answer.\n",
      "\n",
      "Prompt: Why did the system crash?\n",
      "Model Response: Unfortunately, the log doesn't explicitly mention why the system crashed. It only indicates that a \"System crash detected\" occurred at two separate points (10:00 AM and 11:59 PM).\n",
      "\n",
      "However, I can make some educated guesses based on the surrounding events:\n",
      "\n",
      "1. **High CPU usage**: The log shows high CPU usage values just before the first crash (56% at 10:45:12). This could be a contributing factor to the system failure.\n",
      "2. **Network requests fluctuations**: There's a sudden spike in network requests at 11:15:18, followed by a decrease. It's possible that this load change might have put excessive pressure on the system, leading to instability and ultimately a crash.\n",
      "\n",
      "Keep in mind that these are just potential connections I've made based on the log data. Without more detailed information or a direct cause listed in the logs, it's difficult to pinpoint the exact reason for the system crashes.\n",
      "Reference Answer: The system crashed because of an unhandled exception caused by a null pointer in the application code.\n",
      "Score: 3\n",
      "Feedback: The response is generally accurate in that it acknowledges the system crash and attempts to provide explanations based on log data. However, it lacks some important details, such as a clear identification of the root cause of the crash. The model's educated guesses about high CPU usage and network requests fluctuations are plausible but not directly related to the actual reason for the system crash (an unhandled exception caused by a null pointer in the application code). While the response shows some attempt at critical thinking, it fails to provide a clear and specific answer to the question. A more accurate response would have required a deeper analysis of the log data or access to additional information, which is not provided in this scenario.\n",
      "\n",
      "The model's conclusion that \"it's difficult to pinpoint the exact reason for the system crashes\" is an implicit admission that its explanations are speculative rather than definitive. Therefore, while the response shows some potential, it falls short of being comprehensive and accurate, warranting a score of 3.\n",
      "\n",
      "Results saved to ./results/qualitative_evaluation_results_20241005_210357.json\n",
      "Metric: reason_for_restart\n",
      "Score: 2\n",
      "Feedback: The response has some relevance to the question as it mentions a system restart and provides details from the log. However, it is inaccurate in identifying the reason for the restart (system crash detected vs scheduled maintenance update). Additionally, it overlooks the timing mentioned in the reference answer (02:00 AM) and only focuses on the time of the second restart (11:00:00) which is not relevant to the question. The response also jumps to a conclusion about the cause of the system crash without supporting evidence from the log. Overall, while it attempts to engage with the question, it demonstrates significant inaccuracies and omissions compared to the reference answer.\n",
      "Model Response: According to the log, the system restarted twice:\n",
      "\n",
      "1. The first restart occurred at 10:00:01 (initial system startup) is not relevant here.\n",
      "2. The second restart occurred after a \"System crash detected\" event at 11:00:00.\n",
      "\n",
      "This suggests that a system crash was the reason for the restart. However, there isn't any additional information in the log about the cause of the crash.\n",
      "Reference Answer: The system restarted due to a scheduled maintenance update at 02:00 AM.\n",
      "\n",
      "Metric: reason_for_crash\n",
      "Score: 3\n",
      "Feedback: The response is generally accurate in that it acknowledges the system crash and attempts to provide explanations based on log data. However, it lacks some important details, such as a clear identification of the root cause of the crash. The model's educated guesses about high CPU usage and network requests fluctuations are plausible but not directly related to the actual reason for the system crash (an unhandled exception caused by a null pointer in the application code). While the response shows some attempt at critical thinking, it fails to provide a clear and specific answer to the question. A more accurate response would have required a deeper analysis of the log data or access to additional information, which is not provided in this scenario.\n",
      "\n",
      "The model's conclusion that \"it's difficult to pinpoint the exact reason for the system crashes\" is an implicit admission that its explanations are speculative rather than definitive. Therefore, while the response shows some potential, it falls short of being comprehensive and accurate, warranting a score of 3.\n",
      "Model Response: Unfortunately, the log doesn't explicitly mention why the system crashed. It only indicates that a \"System crash detected\" occurred at two separate points (10:00 AM and 11:59 PM).\n",
      "\n",
      "However, I can make some educated guesses based on the surrounding events:\n",
      "\n",
      "1. **High CPU usage**: The log shows high CPU usage values just before the first crash (56% at 10:45:12). This could be a contributing factor to the system failure.\n",
      "2. **Network requests fluctuations**: There's a sudden spike in network requests at 11:15:18, followed by a decrease. It's possible that this load change might have put excessive pressure on the system, leading to instability and ultimately a crash.\n",
      "\n",
      "Keep in mind that these are just potential connections I've made based on the log data. Without more detailed information or a direct cause listed in the logs, it's difficult to pinpoint the exact reason for the system crashes.\n",
      "Reference Answer: The system crashed because of an unhandled exception caused by a null pointer in the application code.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    evaluator = LanguageModelEvaluator(model_name='llama3.1')\n",
    "\n",
    "    # Define your prompts and metric names\n",
    "    prompts = [\n",
    "        \"Why did the system restart?\",\n",
    "        \"Why did the system crash?\"\n",
    "    ]\n",
    "\n",
    "    metric_names = [\n",
    "        \"reason_for_restart\",\n",
    "        \"reason_for_crash\"\n",
    "    ]\n",
    "\n",
    "    # Evaluate the model\n",
    "    results = evaluator.evaluate(\n",
    "        log_file='./sample_log.txt',\n",
    "        ground_truth_file='./ground_truth_qualitative.json',\n",
    "        # log_file='./Mac_2k.log_structured.csv',\n",
    "        # ground_truth_file='./ground_truth_qualitative.json',\n",
    "        prompts=prompts,\n",
    "        metric_names=metric_names\n",
    "    )\n",
    "\n",
    "\n",
    "    # Print the evaluation results\n",
    "    for metric, result in results.items():\n",
    "        print(f\"Metric: {metric}\")\n",
    "        print(f\"Score: {result['score']}\")\n",
    "        print(f\"Feedback: {result['feedback']}\")\n",
    "        print(f\"Model Response: {result['model_response']}\")\n",
    "        print(f\"Reference Answer: {result['reference_answer']}\\n\")\n",
    "\n",
    "    output_file = evaluator.save_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What were the main system performance issues observed in the logs?\n",
      "Model Response: I don’t have information about specific system performance issues from logs. If you could provide more details or context, I would be happy to try and help with a more general inquiry on how to analyze log data for system performance issues.\n",
      "Reference Answer: The system experienced several performance issues, including slow response times, unexpected restarts, and occasional crashes. There were multiple instances of high thermal pressure and memory pressure, which could contribute to performance degradation.\n",
      "Score: 2\n",
      "Feedback: The response shows some relevance to the question by acknowledging a lack of specific information about system performance issues from logs. However, it fails to provide any actual details or insights about the observed issues, which is crucial for addressing the question. While the response suggests a willingness to help with general inquiries on log data analysis, it does not directly relate to the specific performance issues mentioned in the reference answer. A more accurate and detailed response would have been expected given the context of the question.\n",
      "\n",
      "Prompt: Describe the network connectivity problems encountered by the system.\n",
      "Model Response: To provide a comprehensive description of network connectivity problems, I'll outline some common issues that can be encountered:\n",
      "\n",
      "1. **Inability to Establish Connections**:\n",
      "\t* Devices (computers, smartphones, printers, etc.) fail to connect to each other or the internet.\n",
      "\t* No IP address assigned to devices.\n",
      "2. **Intermittent Connectivity**:\n",
      "\t* Network connections drop frequently, requiring repeated reconnections.\n",
      "\t* Data transmission is disrupted, causing delays or lost packets.\n",
      "3. **Slow Network Performance**:\n",
      "\t* Inadequate bandwidth (speed) for data transfer.\n",
      "\t* High latency (delay) in transmitting data across the network.\n",
      "4. **Difficulty Reaching Specific Resources**:\n",
      "\t* Unable to access shared folders, printers, or specific websites.\n",
      "\t* DNS resolution failures prevent devices from accessing resources by their names.\n",
      "5. **Error Messages and Alerts**:\n",
      "\t* \"No internet connection\" error messages appear on devices.\n",
      "\t* Network-related alerts (e.g., \"Connection timed out\") are displayed.\n",
      "6. **Physical Connectivity Issues**:\n",
      "\t* Cables or network cards malfunctioning, causing connectivity problems.\n",
      "\t* Outdated network infrastructure (e.g., outdated routers) leading to performance issues.\n",
      "7. **Security-Related Problems**:\n",
      "\t* Network access denied due to security settings or firewalls blocking connections.\n",
      "\t* Devices infected with malware that disrupt network functionality.\n",
      "\n",
      "To troubleshoot these network connectivity issues, follow a methodical approach:\n",
      "\n",
      "1. Identify the affected devices and resources.\n",
      "2. Check physical connections (cables, power, etc.) and verify they are secure.\n",
      "3. Run network diagnostic tools to identify potential problems (e.g., ping tests).\n",
      "4. Review system logs for error messages related to network connectivity.\n",
      "5. Update device drivers and firmware to ensure compatibility.\n",
      "6. Inspect firewall and security settings to prevent unintended blocks.\n",
      "7. Restart devices, routers, or switches to resolve simple connectivity issues.\n",
      "\n",
      "Remember that specific solutions will depend on the nature of the problem and the system's configuration.\n",
      "Reference Answer: The system faced intermittent network connectivity issues. There were multiple entries related to network changes, DNS problems, and Wi-Fi disconnections. The system often had to re-establish network connections.\n",
      "Score: 4\n",
      "Feedback: The response provides a thorough description of network connectivity problems, covering various issues such as inability to establish connections, intermittent connectivity, slow network performance, difficulty reaching specific resources, error messages and alerts, physical connectivity issues, and security-related problems. The list is detailed and accurate.\n",
      "\n",
      "However, I deducted one point because the response does not directly address the question's request for a description of the network connectivity problems \"encountered by the system.\" While it provides a comprehensive overview of potential network connectivity issues, it doesn't explicitly state what problems were specifically experienced by the system. The reference answer implies that the system faced intermittent network connectivity issues, but this is not directly stated in the response.\n",
      "\n",
      "Overall, the response is still strong and demonstrates a good understanding of network connectivity problems. With some minor revisions to address the specific question's request, it could easily score a 5.\n",
      "\n",
      "Prompt: Summarize the battery status and power management events in the logs.\n",
      "Model Response: However, I don't see any logs provided. Could you please share the logs or describe them to me?\n",
      "\n",
      "If you're referring to system logs related to battery status and power management on a computer or mobile device, here are some possible events that might be summarized:\n",
      "\n",
      "**Battery Status Events:**\n",
      "\n",
      "1. **Battery level changes**: Logs showing the percentage of battery life remaining (e.g., 100%, 75%, 50%).\n",
      "2. **Battery charging/discharging events**: Records of when the battery is being charged or discharged.\n",
      "3. **Low battery warnings**: Notifications when the battery level falls below a certain threshold.\n",
      "\n",
      "**Power Management Events:**\n",
      "\n",
      "1. **System sleep/wake events**: Logs showing when the system goes to sleep or wakes up due to user activity, inactivity, or other triggers.\n",
      "2. **Device shutdown/reboot events**: Records of when the system shuts down or reboots due to power loss, software updates, or other reasons.\n",
      "3. **Power management policy changes**: Configuration updates related to power consumption, such as adjusting screen brightness or turning off unnecessary devices.\n",
      "\n",
      "To provide a more specific summary, please share the actual logs or describe them in more detail!\n",
      "Reference Answer: The log shows several entries related to battery status and power management. The system switched between external power and battery power. There were instances of sleep and wake cycles, likely to conserve battery life.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m\n\u001b[0;32m     13\u001b[0m metric_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_performance\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetwork_connectivity\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecurity_events\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m ]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# log_file='./sample_log.txt',\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ground_truth_file='./ground_truth_qualitative.json',\u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Mac_2k.log_structured.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mground_truth_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./mac_ground_truth_qualitative.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_names\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Print the evaluation results\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric, result \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[2], line 134\u001b[0m, in \u001b[0;36mLanguageModelEvaluator.evaluate\u001b[1;34m(self, log_file, ground_truth_file, prompts, metric_names)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReference Answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreference_answer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 134\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_answer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_rubric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeedback: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeedback\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 62\u001b[0m, in \u001b[0;36mLanguageModelEvaluator.evaluate_response\u001b[1;34m(self, question, response, reference_answer, rubric)\u001b[0m\n\u001b[0;32m     41\u001b[0m         evaluation_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124mYou are an expert evaluator. Your task is to evaluate the following response to a question based on the reference answer and the provided rubric. Provide a score and feedback.\u001b[39m\n\u001b[0;32m     43\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124mEvaluation:\u001b[39m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# Generate evaluation using Llama 3.1\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m         eval_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are an expert evaluator.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m         eval_text \u001b[38;5;241m=\u001b[39m eval_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;66;03m# Extract score and feedback\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\ollama\\_client.py:236\u001b[0m, in \u001b[0;36mClient.chat\u001b[1;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[0m\n\u001b[0;32m    233\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;241m:=\u001b[39m message\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    234\u001b[0m     message[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [_encode_image(image) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeep_alive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m  \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\ollama\\_client.py:99\u001b[0m, in \u001b[0;36mClient._request_stream\u001b[1;34m(self, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_stream\u001b[39m(\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     95\u001b[0m   \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m     96\u001b[0m   stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     97\u001b[0m   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], Iterator[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]]]:\n\u001b[1;32m---> 99\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\ollama\\_client.py:70\u001b[0m, in \u001b[0;36mClient._request\u001b[1;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m httpx\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[1;32m---> 70\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     72\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpx\\_client.py:837\u001b[0m, in \u001b[0;36mClient.request\u001b[1;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m    822\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m    824\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    825\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    826\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    835\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[0;32m    836\u001b[0m )\n\u001b[1;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\Users\\yujie\\anaconda3\\envs\\py310_cuda\\lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    evaluator = LanguageModelEvaluator(model_name='llama3.1')\n",
    "\n",
    "    # Define your prompts and metric names\n",
    "    prompts = [\n",
    "        \"What were the main system performance issues observed in the logs?\",\n",
    "        \"Describe the network connectivity problems encountered by the system.\",\n",
    "        \"Summarize the battery status and power management events in the logs.\",\n",
    "        \"What were the most significant application errors or crashes reported in the logs?\",\n",
    "        \"Identify and explain any security-related events or issues in the logs.\"\n",
    "    ]\n",
    "\n",
    "    metric_names = [\n",
    "        \"system_performance\",\n",
    "        \"network_connectivity\",\n",
    "        \"battery_status\",\n",
    "        \"application_errors\",\n",
    "        \"security_events\"\n",
    "    ]\n",
    "\n",
    "    # Evaluate the model\n",
    "    results = evaluator.evaluate(\n",
    "        # log_file='./sample_log.txt',\n",
    "        # ground_truth_file='./ground_truth_qualitative.json',\n",
    "        log_file='./Mac_2k.log_structured.csv',\n",
    "        ground_truth_file='./mac_ground_truth_qualitative.json',\n",
    "        prompts=prompts,\n",
    "        metric_names=metric_names\n",
    "    )\n",
    "\n",
    "\n",
    "    # Print the evaluation results\n",
    "    for metric, result in results.items():\n",
    "        print(f\"Metric: {metric}\")\n",
    "        print(f\"Score: {result['score']}\")\n",
    "        print(f\"Feedback: {result['feedback']}\")\n",
    "        print(f\"Model Response: {result['model_response']}\")\n",
    "        print(f\"Reference Answer: {result['reference_answer']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
